{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import col,lit\n",
    "from pyspark import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.config(\"spark.driver.host\", \"localhost\").appName(\"SparkByExamples.com\").getOrCreate()\n",
    "conf = pyspark.SparkConf()\n",
    "spark_context = SparkSession.builder.config(conf=conf).getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "americans = spark.createDataFrame([(\"bob\",42),(\"lisa\",59)],[\"first_name\",\"age\"])\n",
    "colombians = spark.createDataFrame([(\"maria\",20),(\"camilo\",31)],[\"first_name\",\"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|first_name|age|\n",
      "+----------+---+\n",
      "|       bob| 42|\n",
      "|      lisa| 59|\n",
      "|     maria| 20|\n",
      "|    camilo| 31|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#UNION\n",
    "res = americans.union(colombians)\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+------+\n",
      "| id|   name|department|salary|\n",
      "+---+-------+----------+------+\n",
      "|  1|Krishna|        IT|  male|\n",
      "+---+-------+----------+------+\n",
      "\n",
      "+---+-------+----------+------+\n",
      "| id|   name|department|salary|\n",
      "+---+-------+----------+------+\n",
      "|  1|Krishna|        IT| 10000|\n",
      "+---+-------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "details = [(1, 'Krishna', 'IT', 'male')]\n",
    "column = ['id', 'name', 'department', 'gender']\n",
    "details1 = [(1, 'Krishna', 'IT', 10000)]\n",
    "column = ['id', 'name', 'department', 'salary']\n",
    "df1 = spark.createDataFrame(details, column)\n",
    "df2 = spark.createDataFrame(details1, column)\n",
    "df1.show()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+------+\n",
      "| id|   name|department|salary|\n",
      "+---+-------+----------+------+\n",
      "|  1|Krishna|        IT|  male|\n",
      "|  1|Krishna|        IT| 10000|\n",
      "+---+-------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.union(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame1 = spark.createDataFrame(\n",
    "[(\"Nitya\", 82.98), (\"Abhishek\", 80.31)],\n",
    "[\"Student Name\", \"Overall Percentage\"]\n",
    ")\n",
    "\n",
    "data_frame2 = spark.createDataFrame(\n",
    "[(\"Sandeep\", 91.123), (\"Rakesh\", 90.51)],\n",
    "[\"Student Name\", \"Overall Percentage\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|Student Name|Overall Percentage|\n",
      "+------------+------------------+\n",
      "|       Nitya|             82.98|\n",
      "|    Abhishek|             80.31|\n",
      "|     Sandeep|            91.123|\n",
      "|      Rakesh|             90.51|\n",
      "+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "UnionExp = data_frame1.union(data_frame2)\n",
    "UnionExp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|Student Name|Overall Percentage|\n",
      "+------------+------------------+\n",
      "|       Nitya|             82.98|\n",
      "|    Abhishek|             80.31|\n",
      "|      Naveen|            91.123|\n",
      "|     Sandeep|             90.51|\n",
      "|      Rakesh|             87.67|\n",
      "+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame1 = spark.createDataFrame(\n",
    "[(\"Nitya\", 82.98), (\"Abhishek\", 80.31)],\n",
    "[\"Student Name\", \"Overall Percentage\"]\n",
    ")\n",
    "# Creating another data frame\n",
    "data_frame2 = spark.createDataFrame(\n",
    "[(91.123, \"Naveen\"), (90.51, \"Sandeep\"), (87.67, \"Rakesh\")],\n",
    "[\"Overall Percentage\", \"Student Name\"]\n",
    ")\n",
    "\n",
    "# Union both the dataframes using unionByName() method\n",
    "byName = data_frame1.unionByName(data_frame2)\n",
    "byName.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+----------------------+\n",
      "|Student Name|Overall Percentage|Department            |\n",
      "+------------+------------------+----------------------+\n",
      "|Bhuwanesh   |82.98             |Computer Science      |\n",
      "|Harshit     |80.31             |Information Technology|\n",
      "|Naveen      |91.123            |null                  |\n",
      "|Piyush      |90.51             |null                  |\n",
      "+------------+------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame1 = spark.createDataFrame(\n",
    "[(\"Bhuwanesh\", 82.98, \"Computer Science\"), (\"Harshit\", 80.31, \"Information Technology\")],\n",
    "[\"Student Name\", \"Overall Percentage\", \"Department\"]\n",
    ")\n",
    "# Creating another dataframe\n",
    "data_frame2 = spark.createDataFrame( [(\"Naveen\", 91.123), (\"Piyush\", 90.51)],\n",
    "                                     [\"Student Name\", \"Overall Percentage\"] )\n",
    "\n",
    "# Union both the dataframes using unionByName() method\n",
    "column_name_morein1df = data_frame1.unionByName(data_frame2, allowMissingColumns=True)\n",
    "column_name_morein1df.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
